{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install numpy\n",
    "!pip install pandas\n",
    "!pip install Connectome-Utilities\n",
    "!pip install connectome-analysis\n",
    "!pip install scipy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The dangers of sampling\n",
    "\n",
    "In connectomics, a lot of data we use stems from experiments where a small subset of a connectome is sampled.\n",
    "That is, brain slices are prepared, then a small number of neurons (e.g., 8) is patched. By making one of the neurons spike and recording from all others, we can then test for the presence of connections.\n",
    "The result is the submatrix of connectivity between the sampled neurons.\n",
    "\n",
    "This leads to the question how representative the samples are for the overall connectome. How reliable are qualitative results obtained this way?\n",
    "\n",
    "In principle this can be investigated mathematically:\n",
    "Let p_true be the probability of connectivity in the actual, full connectome. Then the number of connections found in, e.g., 250 samples of 8 neurons (8 * 7 = 56 pairs) follows a binomial distribution with n=250 * 56, p=p_true. See the code cell below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import binom\n",
    "\n",
    "n = 8 # number of neurons sampled concurrently\n",
    "n_pairs = n * (n - 1) # number of pairs, i.e., possible connections\n",
    "p_true = 0.05 # exemplary value\n",
    "n_submat_sampled = 250 # number of submatrices sampled, i.e., number of slices tested. This is a generous number that would require a lot of work.\n",
    "\n",
    "# The distribution for the results of the sampling\n",
    "distr = binom(n_submat_sampled * n_pairs, p_true)\n",
    "\n",
    "# Expected outcomes: Expected estimate of p from the data and the expected error of the estimate\n",
    "expected_p_estimate = distr.mean() / (n_submat_sampled * n_pairs)\n",
    "expected_err = distr.std() / (n_submat_sampled * n_pairs)\n",
    "display(expected_p_estimate, expected_err)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we see, the experiment is expected to yield the correct estimated connection probability on average, and with a small expected error around it.\n",
    "\n",
    "Can you see the potential issue with this analysis?\n",
    "\n",
    "It assumes that a specific algorithm is a good description of connectivity. In this case, it assumes that connections are formed stochastically independently with uniform probability. That is at the basis of using the binomial distribution. We call this Erdos-Renyi (ER) connectivity - this is in general a very weak model.\n",
    "\n",
    "The binomial distribution resulting from the ER assumption also is much narrower than in actual, biological connectomes. In biological connectomes, the number of connections formed by a single neuron follows a very wide, geometric distribution. And the wider the distribution you sample from is, the larger your expected error:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import geom\n",
    "# Geometric distribution with the expected value\n",
    "distr = geom(1 / (n_submat_sampled * n_pairs * p_true))\n",
    "\n",
    "# Expected outcomes: Expected estimate of p from the data and the expected error of the estimate\n",
    "expected_p_estimate = distr.mean() / (n_submat_sampled * n_pairs)\n",
    "expected_err = distr.std() / (n_submat_sampled * n_pairs)\n",
    "display(expected_p_estimate, expected_err)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see that now the expected relative error is almost 10%. \n",
    "\n",
    "## The bigger problem\n",
    "However, the bigger problem is the assumption that connectivity is:\n",
    "1. spatially non-structured, i.e., independent of neuron locations.\n",
    "2. Stochastically independent, i.e., the presence or absence of one connection does not depend on other connections.\n",
    "\n",
    "The argument for the first assumption is that usually connectivity at low distances is measured. And the lower the range of distances considered, the lower the impact of distance-dependence. We can investigate to what degree that is true."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Recreating the sampling used in experiments stochastically\n",
    "\n",
    "The samples taken are usually depicted in a plot such as the following, from Peng et al., 2024.\n",
    "\n",
    "The relative soma locations of all samples from all slices are considered and indicated. One neuron of the pair is always at the center, the location of the other is indicated as a dot. Color of the dot indicates connectivity."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![image.png](../images/peng_sampling.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see that the samples are mostly at low distances and gradually grow thinner for longer distances.\n",
    "We can recreate that kind of sampling using an actual, biological connectome.\n",
    "\n",
    "We analyze the connectome of the [MICrONS project](https://www.microns-explorer.org). That is an electron-microscopic reconstruction of 1 mm^3 of mouse cortical tissue. This dense reconstruction yields all connections between the neurons in the volume. However, it is not guaranteed to be 100% accurate, as reconstruction errors are possible."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import conntility\n",
    "import pandas\n",
    "import numpy\n",
    "\n",
    "from scipy.spatial.distance import pdist, squareform\n",
    "\n",
    "use_gdrive = True\n",
    "\n",
    "if use_gdrive:\n",
    "    from google.colab import drive\n",
    "    drive.mount('/content/drive')\n",
    "\n",
    "    # Assumes a shortcut to the shared drive has been placed in your Drive.\n",
    "    file_path_in_gdrive = \"/content/drive/MyDrive/NSC6085_Student_Share/April08/data/microns_mm3_connectome_v1181.h5\"\n",
    "    m = conntility.ConnectivityMatrix.from_h5(file_path_in_gdrive, 'condensed')\n",
    "else:\n",
    "    # Alternatively, if the GDrive method does not work, you can download the file separately and place it into the local file system.\n",
    "    # Obtain from: https://doi.org/10.5281/zenodo.13849415\n",
    "    m = conntility.ConnectivityMatrix.from_h5(\"./microns_mm3_connectome_v1181.h5\", 'condensed')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Connectomics studies in cortex often focus on a single cortical layer.\n",
    "Here, we display the counts of cell types associated with all neurons in the connectome. \n",
    "Then we pick a layer, identify the cell types associated with that layer and use the .index function to focus on the connectivity within that layer only."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(\"Connectome contains {0} neurons\".format(len(m)))\n",
    "display(m.vertices.head())\n",
    "display(m.vertices[\"cell_type\"].value_counts().sort_index())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Here we pick L4 and L5. Create list of cell types in that layer. See output of previous cell for list of all cell types.\n",
    "cell_types = [\"L4b\", \"L4a\", \"L4c\"]\n",
    "# Create submatrix of L4 neurons only.\n",
    "m = m.index(\"cell_type\").isin(cell_types)\n",
    "display(\"Sub-connectome between {1} neurons contains {0} neurons\".format(len(m), cell_types))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, an experimenter would create a slice of the tissue. \n",
    "We can use the .slice function to approximate this. The location and angle of the slice can be customized. \n",
    "The slicing method uses the coordinates of the neurons to determine whether they are inside the slice. \n",
    "In the loaded connectome, we have access to the soma locations of neurons in nanometers (\"x_nn\", \"y_nm\", \"z_nm\")."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "\n",
    "# Method to create a sub-connectome within a slice\n",
    "slc = m.slice(0.0, # The angle of the slice. Describes an angle in the plane given by the \"columns_slice\" coordinates.\n",
    "              0.0, # offset of the slice from the center. Here, we stick to the center\n",
    "              200000, # Thickness of the slice. In the units given by the coordinates used. Here: nanometers.\n",
    "              columns_slice=[\"x_nm\", \"z_nm\"], # Rotation of slice defined in these coordinates\n",
    "              column_y=\"y_nm\") # The \"vertical\" direction of the slice\n",
    "\n",
    "plt.scatter(m.vertices[\"x_nm\"], m.vertices[\"z_nm\"], c=\"grey\", s=2, label=\"All neurons\")\n",
    "plt.scatter(slc.vertices[\"x_nm\"], slc.vertices[\"z_nm\"], c=\"red\", s=2, label=\"Neurons in slice\")\n",
    "plt.legend()\n",
    "plt.gca().set_xlabel(\"x (nanometers)\")\n",
    "plt.gca().set_ylabel(\"z (nanometers)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we emulate stochastically the sampling procedure.\n",
    "This uses the .patch_sample function.\n",
    "\n",
    "The function uses the vague observation we made above: That relative locations become gradually less likely with distance. It desribes this as a 2-dimensional gaussian with an exclusion zone for very low distances."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "smpl = slc.patch_sample(\n",
    "    8, # Number of neurons sampled together\n",
    "    [0.0, 0.0], # Placement of the sample. [0, 0] indicates the center of the slice\n",
    "    [  # Sampling is modeled as a 2d gaussian. This is the covariance matrix of said gaussian.\n",
    "        [125000 ** 2, 0.0], # Units are still in nm. 125000 ** 2 indicates a standard deviation of 125 um.\n",
    "        [0.0, 125000 ** 2]  # That means distances between sampled neurons will be around that value.\n",
    "    ],\n",
    "    [\"x_nm\", \"y_nm\"], # Which coordinates define the plane of the slice.append\n",
    "    avoidance_range=20.0 # Pairs closer than this excluded\n",
    ")\n",
    "display(smpl.vertices[[\"x_nm\", \"y_nm\"]] / 1000.0) # Nearby neurons sampled"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can sample many times and compare the relative locations samples visually to the image above.\n",
    "\n",
    "Note that the connectome used is different, so the amount of connectivity can differ. Here, we are trying to match the overall sampling strategy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To put the results\n",
    "all_rel_locs = [] # Relative locations sampled. One entry per pair\n",
    "all_is_con = [] # Which pairs are connected?\n",
    "all_is_rec = [] # Which pairs are reciprocally connected?\n",
    "\n",
    "for _ in range(50): # We sample fifty times\n",
    "    # Create a sampling of eight neurons\n",
    "    smpl = slc.patch_sample(\n",
    "        8, \n",
    "        numpy.random.rand(2) * 25000 - 12500, # Random offset\n",
    "        [ \n",
    "            [125000 ** 2, 0.0], \n",
    "            [0.0, 125000 ** 2]  \n",
    "        ],\n",
    "        [\"x_nm\", \"y_nm\"]\n",
    "    )\n",
    "    # Get the relative locations of neurons sampled. We divide by 1000 to convert from nm to um.\n",
    "    smpl_loc_um = smpl.vertices[[\"y_nm\", \"x_nm\"]].values / 1000\n",
    "    # numpy magic.\n",
    "    rel_loc_um = smpl_loc_um.reshape((-1, 1, 2)) - smpl_loc_um.reshape((1, -1, 2))\n",
    "    # From 8 x 8 x 2 array to 64 x 2 array\n",
    "    rel_loc_um = rel_loc_um.reshape((-1, 2))\n",
    "    # delta x, delta y both 0 means this is a pair of a neuron with itself. We want to exclude them\n",
    "    valid = rel_loc_um.sum(axis=1) != 0\n",
    "    rel_loc_um = rel_loc_um[valid]\n",
    "    # Append relative locations, connectivity and reciprocal connectivity.\n",
    "    all_is_con.extend(smpl.array.astype(bool).flatten()[valid])\n",
    "    all_is_rec.extend(smpl.to_reciprocal().array.astype(bool).flatten()[valid])\n",
    "    all_rel_locs.append(rel_loc_um)\n",
    "\n",
    "# Depict results\n",
    "all_rel_locs = numpy.vstack(all_rel_locs)\n",
    "all_is_con = numpy.array(all_is_con)\n",
    "all_is_rec = numpy.array(all_is_rec)\n",
    "plt.figure(figsize=(3, 3))\n",
    "plt.scatter(all_rel_locs[~all_is_con, 0], all_rel_locs[~all_is_con, 1], s=4, c=[0.7, 0.7, 1.0])\n",
    "plt.scatter(all_rel_locs[all_is_con, 0], all_rel_locs[all_is_con, 1], s=5, c=\"blue\")\n",
    "plt.scatter(all_rel_locs[all_is_rec, 0], all_rel_locs[all_is_rec, 1], s=5, c=\"orange\")\n",
    "plt.gca().set_frame_on(False)\n",
    "plt.axis(\"equal\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sample connectivity and calculate connectivity metrics\n",
    "\n",
    "Now we can sample connectivity systematically. \n",
    "\n",
    "We write a simple function to sample eight neurons at a time over and over, and return the number of connections, the number of reciprocal connections and the mean distance of pairs sampled.\n",
    "\n",
    "In the function we use a \"scale_parameter\" that determines the overall spatial scale that pairs are sampled over. Larger values will lead to sampling at larger pairwise distances."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample(s, scale_parameter, nsmpl, nneuron=8):\n",
    "    ncon = []; nrec = []; npair = []\n",
    "    actual_dists = []\n",
    "    for _ in range(nsmpl):\n",
    "        p = s.patch_sample(nneuron,\n",
    "                           [0, 0],\n",
    "                           [[(scale_parameter * 1000) ** 2, 0],\n",
    "                            [0, (scale_parameter * 1000) ** 2]], \n",
    "                            columns_xy=[\"slice_x\", \"slice_y\"])\n",
    "        r = p.to_reciprocal()\n",
    "        ncon.append(len(p.edges))\n",
    "        nrec.append(len(r.edges))\n",
    "        npair.append(len(p) * (len(p) - 1))\n",
    "        actual_dists.append(pdist(p.vertices[[\"x_nm\", \"y_nm\"]] / 1000).mean())\n",
    "\n",
    "    return pandas.DataFrame({\n",
    "        \"ncon\": ncon,\n",
    "        \"npair\": npair,\n",
    "        \"nrec\": nrec,\n",
    "        \"mn_dist\": actual_dists\n",
    "    })\n",
    "\n",
    "smpl_df = sample(slc, 100.0, 10)\n",
    "display(smpl_df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Overexpression of reciprocity..?\n",
    "One question we can ask is: Is reciprocal, i.e., bidirectional connectivity overexpressed?\n",
    "\n",
    "### Results in favor\n",
    "Perin et al., 2012, PNAS found that in connections between L5 PCs of rats, reciprocal connections are more abundant than expected from the overall connection probability. \n",
    "\n",
    "![image.png](../images/perin_reciprocal.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Results against\n",
    "Conversely, Peng et al., 2024, Science found that in human temporal cortex this is not the case.\n",
    "\n",
    "![image.png](../images/peng_reciprocal.png)\n",
    "\n",
    "How about in our data? (Reminder, this is the MICrONS dataset, i.e., mouse visual cortex)\n",
    "\n",
    "\n",
    "We write a function that analyzes the output of our sampling procedure with respect to this question."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reciprocal_overexpression(df):\n",
    "    # df: pandas.DataFrame. Four columns: npair, ncon, nrec, mn_dist\n",
    "    dfsum = df[[\"npair\", \"ncon\", \"nrec\"]].sum() \n",
    "    puni = dfsum[\"ncon\"] / dfsum[\"npair\"] # The overall connection probability: Connections divided by pairs\n",
    "    prec = dfsum[\"nrec\"] / dfsum[\"npair\"]  # The reciprocal connection probability.\n",
    "    # If connections in both directions are independent, then the probability of both existing is the square of puni.\n",
    "    expected_rec = puni ** 2 # The expected reciprocal connection probability.\n",
    "\n",
    "    # Return the overexpression factor, i.e., actual result divided by expected result.\n",
    "    return pandas.Series([prec / expected_rec], name=\"reciprocal overexpression\",\n",
    "                         index=pandas.Index([numpy.mean(df[\"mn_dist\"])], name=\"mean distance\"))\n",
    "\n",
    "reciprocal_overexpression(smpl_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's gather a lot of samples for various values of the scale parameter.\n",
    "Here, to get more robust data, we sample 16 neurons at a time (16 * 15 pairs)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scales_to_use = [50, 100, 150, 200, 250, 300, 400, 500]\n",
    "nsmpl = 500 #1000\n",
    "\n",
    "numpy.random.seed(12345)\n",
    "smpl_dfs = []\n",
    "for scale in scales_to_use:\n",
    "    print(\"Sampling at scale {0}\".format(scale))\n",
    "    smpl_df = sample(slc, scale, nsmpl, nneuron=16)\n",
    "    smpl_dfs.append(smpl_df)\n",
    "\n",
    "smpls_concat = pandas.concat(smpl_dfs, axis=0, keys=scales_to_use, names=[\"scale\"])\n",
    "rec_overexp_result = smpls_concat.groupby(\"scale\").apply(reciprocal_overexpression)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A quick plot of the results, and how they change with the mean distance sampled."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(rec_overexp_result.reset_index()[\"mean distance\"], rec_overexp_result.values, marker='o')\n",
    "plt.gca().set_xlabel(\"Mean pairwise distance\")\n",
    "plt.gca().set_ylabel(\"Overexpression factor\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We note that the result seems to depend on our sampling! \n",
    "\n",
    "This already indicates that one must be really careful when interpreting data from subsampled connectomics experiments. The results may be specific to the spatial scale considered.\n",
    "\n",
    "Overall, the overexpression of reciprocal connections seems to be larger at higher distances, but the results also vary drastically and seem rather noisy (despite sampling so many pairs). \n",
    "\n",
    "## Considering the full matrix\n",
    "So what is the verdict? How much overexpression of reciprocity is there? Since we have the complete connectome, we can analyze that instead of relying on individual samples.\n",
    "\n",
    "To that end, we calculate the full matrix of pairwise distances and then perform instead an exhaustive sampling: All pairs of neurons within a specified distance cutoff are considered exactly once."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "D = squareform(pdist(m.vertices[[\"x_nm\", \"y_nm\", \"z_nm\"]] / 1000))  # Using um, hence divide by 1000\n",
    "A = m.array  # Adjacency (connectivity) matrix as numpy array\n",
    "R = m.to_reciprocal().array  # Same, but only reciprocal connections are considered.\n",
    "\n",
    "mx_dists = numpy.arange(25, 450, 25)\n",
    "full_smpl_res = []\n",
    "for max_dist in mx_dists:\n",
    "    print(\"Analyzing below {0} um\".format(max_dist))\n",
    "    v = (D < max_dist) & (D > 0)  # distance = 0 along the main diagonal, comparing D > 0 excludes those samples.\n",
    "    puni = A[v].mean(); prec = R[v].mean()\n",
    "    expected_rec = puni ** 2\n",
    "    mean_dists = D[v].mean()\n",
    "    rec_over = prec / expected_rec\n",
    "    full_smpl_res.append(\n",
    "        pandas.Series({\"max distance\": max_dist, \"mean distance\": mean_dists,\n",
    "                       \"reciprocal overexpression\": rec_over})\n",
    "    )\n",
    "full_smpl_res = pandas.concat(full_smpl_res, axis=1).transpose()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(full_smpl_res[\"mean distance\"], full_smpl_res[\"reciprocal overexpression\"], marker='o', label=\"Full connectome\")\n",
    "plt.plot(rec_overexp_result.reset_index()[\"mean distance\"], rec_overexp_result.values, marker='o', label=\"Sampled\")\n",
    "plt.gca().set_xlabel(\"Mean pairwise distance\")\n",
    "plt.gca().set_ylabel(\"Overexpression factor\")\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Result\n",
    "\n",
    "We see that our initial idea was right: Overexpression of reciprocal connections, at least in this particular connectome depends on the overall spatial scale considered.\n",
    "\n",
    "When considering results from sampling small groups of neurons at a time, caution must be applied and the sampled scale must be considered.\n",
    "\n",
    "We also see that this sampling process itself leads to unreliable results.\n",
    "That is another caveat, related to the points illustrated at the start of this notebook: Biological connectivity is characterized by long-tailed distributions, hence sampling less reliable than one might think."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "clean_analyses",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
