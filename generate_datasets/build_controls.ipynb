{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tests:\n",
    "- Amplitudes \n",
    "- Con prob\n",
    "- no reciprocal\n",
    "- distance dependent\n",
    "- down larger than up"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "Connectome types:\n",
    "\n",
    "1. ER control with same connection probability\n",
    "2. ER control with same connection probability and more reciprocal connections\n",
    "2. Added reciprocal connections\n",
    "3. Symmetrized\n",
    "4. Aplitude boosted\n",
    "5. Added connections\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy\n",
    "import pandas\n",
    "import conntility\n",
    "import h5py\n",
    "import scipy\n",
    "\n",
    "numpy.seterr(divide=\"ignore\")\n",
    "numpy.seterr(invalid=\"ignore\")\n",
    "\n",
    "fn = \"../../../artefacts/peng_et_al_human_multi_patch.h5\"\n",
    "\n",
    "def load_all(fn, prefixes):\n",
    "    def load_type(fn, prefix):\n",
    "        h5 = h5py.File(fn, \"r\")\n",
    "        mats = list(h5[prefix].keys())\n",
    "        ret = [conntility.ConnectivityMatrix.from_h5(fn, _m, prefix)\n",
    "            for _m in mats]\n",
    "        idx = pandas.DataFrame({\"matrix_number\": numpy.arange(len(ret))})\n",
    "        return pandas.Series(ret, index=pandas.MultiIndex.from_frame(idx))\n",
    "\n",
    "    mats = pandas.concat([load_type(fn, _p) for _p in prefixes], axis=0,\n",
    "                         names=[\"matrix_type\"], keys=prefixes)\n",
    "    return conntility.ConnectivityGroup(mats)\n",
    "\n",
    "grp = load_all(fn, [\"er\"]) # \"tr\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def avg_amps(mat, node_props, **kwargs):\n",
    "    return pandas.Series(mat.data)\n",
    "\n",
    "cfg_amps = {\n",
    "    \"analyses\":{\n",
    "        \"amplitudes\": {\n",
    "            \"source\": avg_amps,\n",
    "            \"output\": \"Series\"\n",
    "        }\n",
    "    }\n",
    "}\n",
    "amps = grp.analyze(cfg_amps)[\"amplitudes\"].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy\n",
    "import conntility\n",
    "from scipy import sparse\n",
    "import scipy.stats\n",
    "\n",
    "props_to_keep = [\"piadistance\", \"coordinate_1\", \"coordinate_2\", \"coordinate_3\"]\n",
    "noise = {\n",
    "    \"piadistance\": 10.0,\n",
    "    \"coordinate_1\": 25.0,\n",
    "    \"coordinate_2\": 25.0,\n",
    "    \"coordinate_3\": 25.0,\n",
    "}\n",
    "\n",
    "def permutate(con, also_matrix):\n",
    "    idx = numpy.random.permutation(len(con))\n",
    "    props = con._vertex_properties.iloc[idx]\n",
    "    props = props.set_index(pandas.RangeIndex(len(con), name=\"index\"), drop=True)\n",
    "    if not also_matrix:\n",
    "        return conntility.ConnectivityMatrix(con.matrix, vertex_properties=props)\n",
    "    M = con.array[:, idx][idx]\n",
    "    return conntility.ConnectivityMatrix(sparse.coo_matrix(M), vertex_properties=props)\n",
    "\n",
    "\n",
    "def add_random_offset(mat, props_dict):\n",
    "    for col, amp in props_dict.items():\n",
    "        mat._vertex_properties[col] += (amp * numpy.random.rand(len(mat)) - amp/2)\n",
    "    return mat\n",
    "\n",
    "def original(mat, node_props, **kwargs):\n",
    "    props = node_props.set_index(\"index\", drop=True)\n",
    "    return conntility.ConnectivityMatrix(mat, vertex_properties=props[props_to_keep])\n",
    "\n",
    "def er_control_with_same_size_fac(p, amps):\n",
    "    def er_mdl(mat, node_props, **kwargs):\n",
    "        m = numpy.random.rand(*mat.shape) <= p\n",
    "        numpy.fill_diagonal(m, False)\n",
    "        row, col = numpy.nonzero(m)\n",
    "        m_sparse = sparse.coo_matrix((numpy.random.choice(amps, len(row)), (row, col)),\n",
    "                                     shape=m.shape)\n",
    "        props = node_props.set_index(\"index\", drop=True)\n",
    "        ret = conntility.ConnectivityMatrix(m_sparse, vertex_properties=props[props_to_keep])\n",
    "        return add_random_offset(permutate(ret, False), noise)\n",
    "    return er_mdl\n",
    "\n",
    "def boost_amplitudes(f, a):\n",
    "    def boost_mdl(mat, node_props, **kwargs):\n",
    "        m = mat.copy()\n",
    "        m.data *= ((numpy.random.rand(m.nnz) - 0.5) * 2 * a + f)\n",
    "        props = node_props.set_index(\"index\", drop=True)\n",
    "        ret = conntility.ConnectivityMatrix(m, vertex_properties=props[props_to_keep])\n",
    "        return add_random_offset(permutate(ret, True), noise)\n",
    "    return boost_mdl\n",
    "\n",
    "def add_remove_cons(interv_added, amps):\n",
    "    def added_mdl(mat, node_props, **kwargs):\n",
    "        to_add = numpy.random.randint(*interv_added)\n",
    "        mat = mat.tocoo()\n",
    "        edge_tpl = list(zip(mat.row, mat.col))\n",
    "        edge_data = list(mat.data)\n",
    "        if to_add < 0:\n",
    "            for _ in range(-to_add):\n",
    "                if len(edge_tpl) > 0:\n",
    "                    i = numpy.random.randint(len(edge_tpl))\n",
    "                    edge_tpl.pop(i)\n",
    "                    edge_data.pop(i)\n",
    "        elif to_add > 0:\n",
    "            possible_edges = [  # Can be listed exhaustively because matrices are tiny\n",
    "                (a, b) for a in range(len(node_props)) for b in range(len(node_props)) if\n",
    "                a != b and\n",
    "                (a, b) not in edge_tpl\n",
    "            ]\n",
    "            picked = numpy.random.choice(len(possible_edges),\n",
    "                                         numpy.minimum(to_add, len(possible_edges)),\n",
    "                                         replace=False)\n",
    "            edge_tpl = edge_tpl + [possible_edges[_i] for _i in picked]\n",
    "            edge_data = edge_data + list(numpy.random.choice(amps, len(picked)))\n",
    "        if len(edge_tpl) == 0:\n",
    "            m = sparse.coo_matrix(([], ([], [])), shape=mat.shape)\n",
    "        else:\n",
    "            row, col = zip(*edge_tpl)\n",
    "            m = sparse.coo_matrix((edge_data, (row, col)), shape=mat.shape)\n",
    "        props = node_props.set_index(\"index\", drop=True)\n",
    "        ret = conntility.ConnectivityMatrix(m, vertex_properties=props[props_to_keep])\n",
    "        return add_random_offset(permutate(ret, True), noise)\n",
    "    return added_mdl\n",
    "\n",
    "def er_with_rec_boost(p, p_boost, amps):\n",
    "    def er_boost_mdl(mat, node_props, **kwargs):\n",
    "        n = len(node_props)\n",
    "        # Can be listed exhaustively because matrices are tiny\n",
    "        possible_pairs = [(a, b) for b in range(n) for a in range(b + 1, n)]\n",
    "        n_pick = scipy.stats.binom(len(possible_pairs) * 2, p).rvs()\n",
    "        n_rec = scipy.stats.binom(int(n_pick / 2), p * p_boost).rvs()\n",
    "        n_uni = n_pick - (2*n_rec)\n",
    "        edges = []\n",
    "        for i in numpy.random.choice(len(possible_pairs), n_rec, replace=False):\n",
    "            edges.append(possible_pairs[i])\n",
    "            edges.append(possible_pairs[i][::-1])\n",
    "        if n_uni > 0:\n",
    "            possible_edges = [(a, b) for a in range(n) for b in range(n)\n",
    "                              if a != b and (a, b) not in edges]\n",
    "            assert len(possible_edges) >= n_uni\n",
    "            for i in numpy.random.choice(len(possible_edges), n_uni, replace=False):\n",
    "                edges.append(possible_edges[i])\n",
    "        \n",
    "        if len(edges) == 0:\n",
    "            m = sparse.coo_matrix(([], ([], [])), shape=mat.shape)\n",
    "        else:\n",
    "            row, col = zip(*edges)\n",
    "            edge_data = numpy.random.choice(amps, len(row))\n",
    "            m = sparse.coo_matrix((edge_data, (row, col)), shape=mat.shape)\n",
    "        props = node_props.set_index(\"index\", drop=True)\n",
    "        ret = conntility.ConnectivityMatrix(m, vertex_properties=props[props_to_keep])\n",
    "        return add_random_offset(permutate(ret, False), noise)\n",
    "    return er_boost_mdl\n",
    "\n",
    "def swap_based_on_direction(prop, p):\n",
    "    def swapped_mdl(mat, node_props, **kwargs):\n",
    "        mat = mat.tocoo()\n",
    "        edge_tpl = list(zip(mat.row, mat.col))\n",
    "        if len(edge_tpl) == 0:\n",
    "            m = sparse.coo_matrix(([], ([], [])), shape=mat.shape)\n",
    "        else:\n",
    "            is_unidir = [_tpl[::-1] not in edge_tpl for _tpl in edge_tpl]\n",
    "            is_down = [node_props[prop].iloc[_tpl[0]] < \n",
    "                    node_props[prop].iloc[_tpl[1]]\n",
    "                    for _tpl in edge_tpl]\n",
    "            is_swap = numpy.array(is_unidir) & numpy.array(is_down) & (numpy.random.rand(len(is_unidir)) < p)\n",
    "            edge_tpl_out = [_tpl[::-1] if _swap else _tpl \n",
    "                            for _tpl, _swap in zip(edge_tpl, is_swap)]\n",
    "            row, col = zip(*edge_tpl_out)\n",
    "            edge_data = mat.data\n",
    "            m = sparse.coo_matrix((edge_data, (row, col)), shape=mat.shape)\n",
    "        props = node_props.set_index(\"index\", drop=True)\n",
    "        ret = conntility.ConnectivityMatrix(m, vertex_properties=props[props_to_keep])\n",
    "        return add_random_offset(permutate(ret, True), noise)\n",
    "    return swapped_mdl\n",
    "\n",
    "def add_reciprocal(p):\n",
    "    def rec_mdl(mat, node_props, **kwargs):\n",
    "        mat = mat.tocoo()\n",
    "        edge_tpl = list(zip(mat.row, mat.col))\n",
    "        if len(edge_tpl) == 0:\n",
    "            m = sparse.coo_matrix(([], ([], [])), shape=mat.shape)\n",
    "        else:\n",
    "            is_unidir = numpy.array([_tpl[::-1] not in edge_tpl for _tpl in edge_tpl])\n",
    "            n_swap = scipy.stats.binom(int(numpy.sum(is_unidir) / 2), p).rvs()\n",
    "            if n_swap == 0:\n",
    "                edge_tpl_out = edge_tpl\n",
    "            else:\n",
    "                rnd = numpy.random.permutation(numpy.nonzero(is_unidir)[0])\n",
    "                to_swap = rnd[:n_swap]\n",
    "                to_keep = numpy.hstack([rnd[n_swap:-n_swap], numpy.nonzero(~is_unidir)[0]])\n",
    "                edge_tpl_out = [edge_tpl[i] for i in to_swap] +\\\n",
    "                            [edge_tpl[i][::-1] for i in to_swap] +\\\n",
    "                            [edge_tpl[i] for i in to_keep]\n",
    "            assert len(edge_tpl) == len(edge_tpl_out)\n",
    "            row, col = zip(*edge_tpl_out)\n",
    "            edge_data = mat.data\n",
    "            m = sparse.coo_matrix((edge_data, (row, col)), shape=mat.shape)\n",
    "        props = node_props.set_index(\"index\", drop=True)\n",
    "        ret = conntility.ConnectivityMatrix(m, vertex_properties=props[props_to_keep])\n",
    "        return add_random_offset(permutate(ret, True), noise)\n",
    "    return rec_mdl\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "numpy.random.permutation([\"mystery_{0}\".format(i + 1)\n",
    "                          for i in range(7)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "analyses = [\n",
    "        {\n",
    "            \"source\": original,\n",
    "            \"output\": \"Object\"\n",
    "        },\n",
    "        {\n",
    "            \"source\": er_control_with_same_size_fac(0.158, amps),\n",
    "            \"output\": \"Object\",\n",
    "        },\n",
    "        {\n",
    "            \"source\": boost_amplitudes(1.25, 0.15),\n",
    "            \"output\": \"Object\",\n",
    "        },\n",
    "        {\n",
    "            \"source\": add_remove_cons([-1, 3], amps),\n",
    "            \"output\": \"Object\",\n",
    "        },\n",
    "        {\n",
    "            \"source\": er_with_rec_boost(0.158, 3, amps),\n",
    "            \"output\": \"Object\"\n",
    "        },\n",
    "        {\n",
    "            \"source\": swap_based_on_direction(\"piadistance\", 0.28),\n",
    "            \"output\": \"Object\"\n",
    "        },\n",
    "        {\n",
    "            \"source\": add_reciprocal(0.3),\n",
    "            \"output\": \"Object\"\n",
    "        }\n",
    "]\n",
    "rnd = numpy.random.permutation([\"mystery_{0}\".format(i + 1) for i in range(7)])\n",
    "cfg = {\n",
    "    \"analyses\": dict([(name, analysis) for name, analysis in zip(rnd, analyses)])\n",
    "}\n",
    "\n",
    "M = grp.analyze(cfg)\n",
    "\n",
    "for k in M.keys():\n",
    "    midx = M[k].index.to_frame()\n",
    "    midx[\"matrix_type\"] = k\n",
    "    M[k].index = pandas.MultiIndex.from_frame(midx)\n",
    "M = conntility.ConnectivityGroup(pandas.concat(M.values(), axis=0))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cfg_tests = {\n",
    "    \"analyses\":{\n",
    "        \"connection_strengths\": {\n",
    "            \"source\": \"./my_tests.py\",\n",
    "            \"method\": \"edge_values\",\n",
    "            \"output\": \"Series\",\n",
    "        },\n",
    "        \"connection_probability\":{ \n",
    "            \"source\": \"./my_tests.py\",\n",
    "            \"method\": \"connection_probability\",\n",
    "            \"output\": \"Value\",\n",
    "        },\n",
    "        \"reciprocal_probability\":{ \n",
    "            \"source\": \"./my_tests.py\",\n",
    "            \"method\": \"reciprocal_probability\",\n",
    "            \"output\": \"Value\",\n",
    "        },\n",
    "        \"extra_and_missing_rec\":\n",
    "        { \n",
    "            \"source\": \"./my_tests.py\",\n",
    "            \"method\": \"extra_and_missing_reciprocals\",\n",
    "            \"args\": [0.158],\n",
    "            \"output\": \"Value\",\n",
    "        },\n",
    "        \"down_minus_up\":\n",
    "        { \n",
    "            \"source\": \"./my_tests.py\",\n",
    "            \"method\": \"count_downwards_minus_upwards\",\n",
    "            \"args\": [\"piadistance\"],\n",
    "            \"output\": \"Value\",\n",
    "        }, \n",
    "        \"p_prox\": {\n",
    "            \"source\": \"./my_tests.py\",\n",
    "            \"method\": \"connection_probability_within\",\n",
    "            \"output\": \"Series\",\n",
    "            \"args\": [[\"coordinate_1\", \"coordinate_2\", \"coordinate_3\"],\n",
    "                     [0.0, 100.0]\n",
    "            ]\n",
    "        },\n",
    "        \"p_dist\": {\n",
    "            \"source\": \"./my_tests.py\",\n",
    "            \"method\": \"connection_probability_within\",\n",
    "            \"output\": \"Series\",\n",
    "            \"args\": [[\"coordinate_1\", \"coordinate_2\", \"coordinate_3\"],\n",
    "                     [100.0, 5000.0]\n",
    "            ]\n",
    "        }\n",
    "    }\n",
    "}\n",
    "\n",
    "res = M.analyze(cfg_tests)\n",
    "\n",
    "# Amplitudes is 0.64\n",
    "strength_matches = lambda _x: scipy.stats.ttest_1samp(_x, 0.64).pvalue > 0.05\n",
    "\n",
    "# Connection prob is 0.158\n",
    "con_prob_matches = lambda _x: scipy.stats.ttest_1samp(_x, 0.158).pvalue > 0.05\n",
    "\n",
    "# No reciprocal overexpression\n",
    "no_rec_overexpr = lambda _x: scipy.stats.ttest_1samp(_x, 0.0).pvalue > 0.05\n",
    "\n",
    "# Distance-dependence\n",
    "is_dist_dep = lambda _x: scipy.stats.ttest_rel(_x[0], _x[1]).pvalue <= 0.05\n",
    "\n",
    "# Directionality\n",
    "is_directional = lambda _x: scipy.stats.ttest_1samp(_x, 0.0).pvalue <= 0.05\n",
    "\n",
    "\n",
    "evaluated = pandas.concat([\n",
    "    res[\"connection_strengths\"].groupby(\"matrix_type\").apply(strength_matches),\n",
    "    res[\"connection_probability\"].dropna().groupby(\"matrix_type\").apply(con_prob_matches),\n",
    "    res[\"extra_and_missing_rec\"].dropna().groupby(\"matrix_type\").apply(no_rec_overexpr),\n",
    "    pandas.concat([res[\"p_prox\"], res[\"p_dist\"]], axis=1).dropna().groupby(\"matrix_type\").apply(is_dist_dep),\n",
    "    res[\"down_minus_up\"].dropna().groupby(\"matrix_type\").apply(is_directional)\n",
    "], axis=1)\n",
    "evaluated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "if not os.path.exists(\"../datasets\"):\n",
    "    os.makedirs(\"../datasets\")\n",
    "M.to_h5(\"../datasets/mystery_con_mats.h5\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conntility_tech",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
